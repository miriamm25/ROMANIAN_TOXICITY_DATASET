# TORCH-RaR Configuration
# =============================================================================

# LLM Provider Configuration
# Options: openrouter, vllm, litellm_proxy
llm_provider: vllm

# =============================================================================
# OpenRouter Configuration (default provider)
# =============================================================================

# Get your API key from https://openrouter.ai/keys
openrouter_api_key: ${OPENROUTER_API_KEY}  # Set via environment variable
openrouter_base_url: https://openrouter.ai/api/v1

# Model selection for OpenRouter
rubric_generator_model: openrouter/openai/gpt-4o
judge_model: openrouter/openai/gpt-4o-mini

# =============================================================================
# vLLM Configuration (local Docker deployment)
# =============================================================================

vllm_base_url: http://localhost:11434/v1
vllm_model_name: deepseek-r1:70b

# =============================================================================
# LiteLLM Proxy Configuration
# =============================================================================

litellm_proxy_url: http://localhost:4000
litellm_api_key: null  # Set if your proxy requires authentication

# =============================================================================
# Dataset Configuration
# =============================================================================

dataset_name: olimpia20/toxicity-dataset-ro-master
dataset_split: train
output_dir: ./output

# =============================================================================
# Rubric Configuration
# =============================================================================

min_rubric_items: 7
max_rubric_items: 20

# =============================================================================
# Prompt Templates Configuration
# =============================================================================

prompt_templates:
  directory: prompts/
  default_domain: toxicity
  domains:
    toxicity:
      tasks:
        - "Evaluate Romanian political discourse for toxicity"
        - "Identify personal attacks, threats, and group hatred"
      context: "Focus on Romanian language and cultural context"
    medical:
      tasks:
        - "Evaluate medical response accuracy and safety"
        - "Check for appropriate disclaimers"
      context: "Medical domain requires safety-first evaluation"
    science:
      tasks:
        - "Evaluate scientific reasoning and accuracy"
        - "Check for proper methodology references"
      context: null

# =============================================================================
# Processing Configuration
# =============================================================================

batch_size: 20
max_concurrent_requests: 15
request_timeout: 120
max_retries: 3
max_tokens: 8192  # Maximum tokens in LLM response (reduce for smaller context models)

# =============================================================================
# Reward Weights (for explicit aggregation, following RaR paper)
# =============================================================================
# NOTE: Individual rubric weights are now defined per-rubric in rubric_generator.py
# following guide Section 5.1 specifications:
#
# Essential (E1-E4): 1.0, 0.95, 0.90, 0.90
# Important (I1-I4): 0.70, 0.65, 0.60, 0.60
# Pitfall (P1-P3):  -0.60, -0.65, -0.50 (negative = penalties)
#
# These category defaults are used as fallbacks for dynamically generated rubrics:
weight_essential: 1.0
weight_important: 0.7
weight_optional: 0.3
weight_pitfall: -0.6

# =============================================================================
# Logging Configuration
# =============================================================================

logging:
  level: "INFO"           # DEBUG, INFO, WARNING, ERROR
  directory: "logs"       # Directory for log files
  json_format: true       # Output JSON to log files for analysis
  rotation: "10 MB"       # When to rotate log files
  retention: "7 days"     # How long to keep old logs

# =============================================================================
# Cache Configuration
# =============================================================================

cache:
  enabled: true
  directory: ".cache/rubrics"
  ttl_seconds: 2592000    # 30 days
  size_limit_gb: 1.0

# =============================================================================
# Progress Display
# =============================================================================

show_progress: true
